ğŸš€ Agentic LLM With Tools

An Agentic AI Chatbot built using Groq LLM + Tavily Web Search API with dynamic tool-calling capability.

This project demonstrates how to build a real LLM Agent that can:

ğŸ’¬ Maintain conversation memory

ğŸ§  Switch personalities (Marvel Multiverse Mode)

ğŸŒ Call external tools (Web Search)

ğŸ”„ Handle tool-calling loop correctly

ğŸ›  Work in a CLI interactive environment

ğŸ§  Features

âœ… Groq LLM Integration (llama-3.1-8b-instant)

âœ… Function / Tool Calling

âœ… Tavily Real-Time Web Search

âœ… Conversation Memory

âœ… Interactive CLI Chat

âœ… TypeScript Implementation

âœ… Secure .env Handling

ğŸ— Architecture
User Input (CLI)
        â”‚
        â–¼
Conversation Memory (messages[])
        â”‚
        â–¼
Groq LLM (Decision Phase)
        â”‚
        â”œâ”€â”€ Direct Response
        â”‚
        â””â”€â”€ Tool Call (webSearch)
                â”‚
                â–¼
           Tavily API
                â”‚
                â–¼
        Tool Result Added to Memory
                â”‚
                â–¼
        Groq LLM (Final Response Phase)
                â”‚
                â–¼
           Assistant Output
âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone Repository
git clone https://github.com/Shanu529/Agentic-LLM-With-Tools.git
cd Agentic-LLM-With-Tools
2ï¸âƒ£ Install Dependencies

Install all required dependencies for this TypeScript GenAI project:

npm install
3ï¸âƒ£ Create .env File

Create a file named .env in the root directory:

GROQ_API_KEY=your_groq_api_key
TAVILY_KEY_API=your_tavily_api_key

âš ï¸ Never push your .env file to GitHub.

4ï¸âƒ£ Run Development Mode
npm run dev

OR

npx tsx src/app.ts
ğŸ›  Tech Stack

Groq SDK

Tavily API

TypeScript

Node.js

Readline (CLI Interface)

dotenv

ğŸ”„ How It Works

User types input in CLI.

Message is stored in memory.

LLM decides whether to respond directly or call a tool.

If tool is called â†’ Tavily API fetches real-time data.

Tool result is added back into conversation.

LLM generates final intelligent response.
